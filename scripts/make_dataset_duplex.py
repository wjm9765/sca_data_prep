#!/usr/bin/env -S uv run python

import argparse
import json
import sys
from pathlib import Path
from tqdm import tqdm

from transformers import Qwen3OmniMoeProcessor

try:
    # dataset_utils.py에서 함수 가져오기
    from sca_data.dataset_utils import parse_aligned_script, duplex_data
except ImportError as e:
    print("[Error] Failed to import 'sca_data'.")
    print(f"Debug info - sys.path: {sys.path}")
    print(f"Error details: {e}")
    sys.exit(1)

# -----------------------------------------------------------------------------
# [Config] 기본 설정
# -----------------------------------------------------------------------------
DEFAULT_INPUT_DIR = Path("./Multi-stream Spontaneous Conversation Training Dataset")
DEFAULT_MODEL_PATH = "Qwen/Qwen3-Omni-30B-A3B-Instruct"
# -----------------------------------------------------------------------------


def save_parsed_scripts(data_dir: Path, output_dir: Path, model_path: str):
    """
    [Mode: Script]
    TXT 파일을 파싱하여 JSON으로 저장 (토크나이징 확인용)
    """
    txt_dir = data_dir / "TXT"

    if not txt_dir.exists():
        raise FileNotFoundError(f"TXT folder not found in {data_dir}")

    output_dir.mkdir(parents=True, exist_ok=True)

    print(f">>> [Mode: Script] Loading Tokenizer from {model_path}...")
    try:
        processor = Qwen3OmniMoeProcessor.from_pretrained(
            model_path, trust_remote_code=True
        )
        tokenizer = processor.tokenizer  # type:ignore
    except Exception as e:
        print(f"[Error] Failed to load model/tokenizer: {e}")
        sys.exit(1)

    print(f">>> Parsing scripts from {txt_dir} and saving to {output_dir}...")

    files = list(txt_dir.glob("*.txt"))
    if not files:
        print("[Warning] No .txt files found.")
        return

    for txt_file in tqdm(files, desc="Parsing & Saving"):
        # parse_aligned_script는 tokenizer를 인자로 받음
        events = parse_aligned_script(txt_file, tokenizer)

        save_name = txt_file.stem + ".json"
        save_path = output_dir / save_name

        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(events, f, ensure_ascii=False, indent=2)

    print(f">>> Done! JSON files saved at: {output_dir}")


def build_hf_dataset(data_dir: Path, model_path: str, output_dir: Path):
    """
    [Mode: Dataset]
    Hugging Face 데이터셋 빌드 및 저장 (Arrow 포맷)
    """
    print(f">>> [Mode: Dataset] Building Hugging Face Dataset from {data_dir}")
    print(f">>> Output Cache Dir: {output_dir}")
    print(f">>> Model Path: {model_path}")

    if not (data_dir / "WAV").exists() or not (data_dir / "TXT").exists():
        raise FileNotFoundError(
            f"Input directory must contain 'WAV' and 'TXT' folders inside {data_dir}"
        )

    # duplex_data 함수 호출 (dataset_utils.py)
    # cache_dir에 결과가 저장됨
    duplex_data(data_dir=data_dir, cache_dir=output_dir, model_path=model_path)

    print(f">>> Done! Full dataset saved at: {output_dir}")


def main():
    parser = argparse.ArgumentParser(description="SCA Duplex Dataset Converter")

    parser.add_argument(
        "--mode",
        type=str,
        choices=["script", "dataset"],
        required=True,
        help="'script': Save parsed JSONs / 'dataset': Build full HF dataset",
    )

    parser.add_argument(
        "--input",
        type=str,
        default=str(DEFAULT_INPUT_DIR),
        help=f"Input data directory (Default: {DEFAULT_INPUT_DIR})",
    )

    parser.add_argument(
        "--output",
        type=str,
        default=None,  # None이면 아래에서 자동 할당
        help="Output directory (Optional)",
    )

    parser.add_argument(
        "--model_path",
        type=str,
        default=DEFAULT_MODEL_PATH,
        help="Qwen model path for tokenizer",
    )

    args = parser.parse_args()

    input_path = Path(args.input)

    if args.output:
        output_path = Path(args.output)
    else:
        if args.mode == "script":
            output_path = Path("./parsed_json")
        else:
            output_path = Path("./dataset")

    if not input_path.exists():
        print(f"[Error] Input directory not found: {input_path}")
        print(f"Current working directory: {Path.cwd()}")
        sys.exit(1)

    # 실행 분기
    if args.mode == "script":
        save_parsed_scripts(input_path, output_path, args.model_path)

    elif args.mode == "dataset":
        build_hf_dataset(input_path, args.model_path, output_path)


if __name__ == "__main__":
    main()
