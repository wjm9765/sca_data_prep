{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T12:10:11.223102Z",
     "start_time": "2025-11-23T12:10:09.887538Z"
    }
   },
   "source": [
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import dotenv\n",
    "import soundfile as sf\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from audio_processing import get_vad_slices\n",
    "from models.audio import SlicedAudioFile\n",
    "from models.events import ComedySession\n",
    "\n",
    "dotenv.load_dotenv(dotenv_path=dotenv.find_dotenv())\n",
    "\n",
    "DATASET_DIR = Path(\"./dataset\").absolute()\n",
    "SLICE_CACHE = DATASET_DIR / \"slice_cache.jsonl\"\n",
    "AUDIO_DIR = (DATASET_DIR / \"audio_outputs\").absolute()\n",
    "audio_files = list(AUDIO_DIR.glob('*.flac'))\n",
    "\n",
    "print(f'Found {len(audio_files)} audio files in {AUDIO_DIR}')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riverfog7/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 audio files in /Users/riverfog7/Workspace/SCA/data_prep/dataset/audio_outputs\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T12:10:11.231074Z",
     "start_time": "2025-11-23T12:10:11.226070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_list: List[SlicedAudioFile] = []\n",
    "\n",
    "if not SLICE_CACHE.exists():\n",
    "    for audio_path in tqdm(audio_files):\n",
    "        tqdm.write(f'Processing {audio_path.name}...')\n",
    "        file_list.append(get_vad_slices(audio_path, slice_min=2))\n",
    "\n",
    "    with open(SLICE_CACHE, 'w') as f:\n",
    "        for file in file_list:\n",
    "            f.write(file.model_dump_json() + '\\n')\n",
    "\n",
    "with open(SLICE_CACHE, 'r') as f:\n",
    "    for line in f:\n",
    "        file_list.append(SlicedAudioFile.model_validate_json(line))\n",
    "\n",
    "chunk_lst = [slice for file in file_list for slice in file.slices]\n",
    "print(f\"Total {sum(len(file.slices) for file in file_list)} slices found in {len(file_list)} audio files.\")"
   ],
   "id": "6913355cd154977d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 660 slices found in 31 audio files.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T12:10:11.237131Z",
     "start_time": "2025-11-23T12:10:11.234521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_segmented_audio_with_timestamps(base_path: Path, slice, segment_duration: int = 6) -> List[HumanMessage]:\n",
    "    \"\"\"\n",
    "    Split audio slice into segments with text timestamp markers.\n",
    "\n",
    "    Args:\n",
    "        segment_duration: Duration of each segment (default 6s, optimal for AuT encoder)\n",
    "\n",
    "    Returns:\n",
    "        List of HumanMessage objects with interleaved text/audio content\n",
    "    \"\"\"\n",
    "    audio_path = base_path / slice.file\n",
    "    info = sf.info(audio_path)\n",
    "    sr = info.samplerate\n",
    "\n",
    "    start_frame = int(slice.start_time * sr)\n",
    "    stop_frame = int(slice.end_time * sr)\n",
    "\n",
    "    total_frames = stop_frame - start_frame\n",
    "    segment_frames = int(segment_duration * sr)\n",
    "\n",
    "    content = [{\"type\": \"text\", \"text\": f\"T={slice.start_time:.1f}s (CHUNK START)\"}]\n",
    "\n",
    "    current_time = slice.start_time\n",
    "    for i in range(0, total_frames, segment_frames):\n",
    "        segment_start = start_frame + i\n",
    "        segment_stop = min(segment_start + segment_frames, stop_frame)\n",
    "\n",
    "        # Read audio segment\n",
    "        data, _ = sf.read(audio_path, start=segment_start, stop=segment_stop, dtype='int16')\n",
    "\n",
    "        # Encode to base64\n",
    "        buffered = io.BytesIO()\n",
    "        sf.write(buffered, data, sr, format='WAV')\n",
    "        audio_b64 = base64.b64encode(buffered.getvalue()).decode()\n",
    "\n",
    "        # Add audio segment\n",
    "        content.append({\n",
    "            \"type\": \"audio_url\",\n",
    "            \"audio_url\": {\"url\": f\"data:audio/wav;base64,{audio_b64}\"}\n",
    "        })\n",
    "\n",
    "        # Add timestamp marker after each segment\n",
    "        current_time += segment_duration\n",
    "        if current_time < slice.end_time:\n",
    "            content.append({\"type\": \"text\", \"text\": f\"T={min(current_time, slice.end_time):.1f}s\"})\n",
    "\n",
    "    content.append({\"type\": \"text\", \"text\": f\"T={slice.end_time:.1f}s (CHUNK END)\"})\n",
    "    content.append({\n",
    "        \"type\": \"text\",\n",
    "        \"text\": f\"Transcribe the above audio from video '{slice.file}'. Use T= markers for accurate timestamp prediction.\"\n",
    "    })\n",
    "\n",
    "    # Return as single HumanMessage with multipart content\n",
    "    return [HumanMessage(content=content)]"
   ],
   "id": "6a18ebca1610e378",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T12:10:11.291788Z",
     "start_time": "2025-11-23T12:10:11.241302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = get_segmented_audio_with_timestamps(AUDIO_DIR, chunk_lst[4], segment_duration=4)\n",
    "[val for val in res[0].content if val['type'] == 'text']"
   ],
   "id": "69facdfa38efc6ae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'text', 'text': 'T=482.0s (CHUNK START)'},\n",
       " {'type': 'text', 'text': 'T=486.0s'},\n",
       " {'type': 'text', 'text': 'T=490.0s'},\n",
       " {'type': 'text', 'text': 'T=494.0s'},\n",
       " {'type': 'text', 'text': 'T=498.0s'},\n",
       " {'type': 'text', 'text': 'T=502.0s'},\n",
       " {'type': 'text', 'text': 'T=506.0s'},\n",
       " {'type': 'text', 'text': 'T=510.0s'},\n",
       " {'type': 'text', 'text': 'T=514.0s'},\n",
       " {'type': 'text', 'text': 'T=518.0s'},\n",
       " {'type': 'text', 'text': 'T=522.0s'},\n",
       " {'type': 'text', 'text': 'T=526.0s'},\n",
       " {'type': 'text', 'text': 'T=530.0s'},\n",
       " {'type': 'text', 'text': 'T=534.0s'},\n",
       " {'type': 'text', 'text': 'T=538.0s'},\n",
       " {'type': 'text', 'text': 'T=542.0s'},\n",
       " {'type': 'text', 'text': 'T=546.0s'},\n",
       " {'type': 'text', 'text': 'T=550.0s'},\n",
       " {'type': 'text', 'text': 'T=554.0s'},\n",
       " {'type': 'text', 'text': 'T=558.0s'},\n",
       " {'type': 'text', 'text': 'T=562.0s'},\n",
       " {'type': 'text', 'text': 'T=566.0s'},\n",
       " {'type': 'text', 'text': 'T=570.0s'},\n",
       " {'type': 'text', 'text': 'T=574.0s'},\n",
       " {'type': 'text', 'text': 'T=578.0s'},\n",
       " {'type': 'text', 'text': 'T=582.0s'},\n",
       " {'type': 'text', 'text': 'T=586.0s'},\n",
       " {'type': 'text', 'text': 'T=590.0s'},\n",
       " {'type': 'text', 'text': 'T=594.0s'},\n",
       " {'type': 'text', 'text': 'T=598.0s'},\n",
       " {'type': 'text', 'text': 'T=602.0s'},\n",
       " {'type': 'text', 'text': 'T=604.5s (CHUNK END)'},\n",
       " {'type': 'text',\n",
       "  'text': \"Transcribe the above audio from video 'Judge Me If You Can! Ep01 ft. @ComicKaustubhAgarwal & @yuvrajdua4094.flac'. Use T= markers for accurate timestamp prediction.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T12:10:11.482774Z",
     "start_time": "2025-11-23T12:10:11.294708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an advanced audio analysis AI specializing in Standup Comedy transcription.\n",
    "Your task is to listen to the audio and generate a high-precision JSON timeline according to this schema:\n",
    "{schema}\n",
    "\n",
    "### TIMESTAMP REFERENCE SYSTEM:\n",
    "- The audio is divided into segments with text timestamp markers (e.g., \"T=5.0s\", \"T=11.0s\")\n",
    "- Use these markers to accurately predict event timestamps\n",
    "- **DO NOT transcribe the timestamp markers themselves** - they are timing references only\n",
    "- All predicted timestamps must be between the CHUNK START and CHUNK END markers\n",
    "\n",
    "**Example interpretation:**\n",
    "- Text marker: \"T=5.0s\"\n",
    "- Audio: *audience laughter*\n",
    "- Text marker: \"T=11.0s\"\n",
    "- Audio: \"That's the problem with dating apps\"\n",
    "→ Laughter timestamp: ~5.3s (shortly after T=5.0s marker)\n",
    "→ Speech start: ~11.2s (shortly after T=11.0s marker)\n",
    "\n",
    "### CRITICAL TRANSCRIPTION PROTOCOLS:\n",
    "\n",
    "1. **CONTEXT & SEGMENTATION (Chunk Processing):**\n",
    "   - **Partial Input:** The provided audio is a specific **chunk** sliced from a longer performance. It is NOT the full video.\n",
    "   - **Boundary Handling:** Do not hallucinate words that might be cut off at the very start or very end of the file. Transcribe exactly what is audible within this slice.\n",
    "   - **Scope:** Your timeline must strictly reflect events occurring within this specific audio segment.\n",
    "\n",
    "2. **SOURCE SEPARATION (Comedian vs. Audience vs. Environment):**\n",
    "   - You must acoustically distinguish between the three distinct sound sources defined in the schema:\n",
    "   - **ComedianEvent:** Speech, breathing, or self-laughter coming specifically from the microphone/performer.\n",
    "   - **AudienceEvent:** Strictly crowd reactions (cheering, applause, collective laughter, heckling).\n",
    "   - **EnvironmentEvent:** Non-human or background sounds (Music, technical noise, accidental noise).\n",
    "\n",
    "3. **TEMPORAL DYNAMICS (Overlaps):**\n",
    "   - **Allow Overlaps:** Real comedy is fluid. Audience laughter often begins *before* the comedian finishes their punchline.\n",
    "   - **Timestamp Accuracy:** Capture these overlaps precisely using the T= markers as anchors. Do not artificially force events to happen sequentially if they occur simultaneously.\n",
    "\n",
    "4. **CLASSIFICATION & 'OTHER' HANDLING:**\n",
    "   - **Strict Categorization:** Attempt to categorize sounds using the specific Enums provided in the schema (e.g., 'laughter', 'applause', 'mic_feedback').\n",
    "   - **The 'Other' Fallback:** If a sound occurs that does not strictly fit the provided categories, you MUST select the **'other'** option for the `type` or `category` field.\n",
    "   - **Self-Explanation:** When you select **'other'**, you must explicitly describe the sound in the `content` field.\n",
    "     - *Example:* If a baby cries in the crowd (and 'crying' isn't an option), set `reaction_type='other'` and `content='[baby crying]'`.\n",
    "     - *Example:* If a chair squeaks on stage (and 'squeak' isn't an option), set `event_type='other'` and `content='[chair squeak]'`.\n",
    "   - **Speech Content:** For standard speech, transcribe verbatim.\n",
    "\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"user_messages\"),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    model=os.getenv('VLLM_MODEL'),\n",
    "    base_url=os.getenv('VLLM_URL'),\n",
    "    max_tokens=8192,\n",
    ").with_structured_output(ComedySession).with_retry()\n",
    "\n",
    "chain = template | model"
   ],
   "id": "60ad3289078204eb",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T12:11:21.457484Z",
     "start_time": "2025-11-23T12:10:11.485655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunk_try = chunk_lst[1]\n",
    "user_messages = get_segmented_audio_with_timestamps(AUDIO_DIR, chunk_try, segment_duration=6)\n",
    "\n",
    "chain.invoke({\n",
    "    \"user_messages\": user_messages,\n",
    "    \"schema\": ComedySession.model_json_schema(),\n",
    "})"
   ],
   "id": "2cb72aa8dbfd56ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComedySession(video_id='Judge Me If You Can! Ep01 ft. @ComicKaustubhAgarwal & @yuvrajdua4094.flac', timeline=[ComedianEvent(start=122.2, end=124.8, role='comedian', content='इसे लाल पेस्ट का पता है ना?', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=125.3, end=126.4, role='comedian', content='चलिए तो कराएँ।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=127.3, end=127.6, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=127.7, end=129.6, role='comedian', content='लाल पेस्ट वाले इसको बोलते हैं कि आपके...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=129.7, end=131.0, role='comedian', content='full body में दो महीने लगे हैं भाई।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=131.4, end=133.1, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=133.1, end=134.2, role='comedian', content='आपको...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=134.2, end=136.5, role='comedian', content='क्या हम contestant को बुलाने से पहले ही...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=137.1, end=138.8, role='comedian', content='पूछ लें इन लोगों का stake पे क्या लगा हुआ है?', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=139.4, end=141.3, role='comedian', content='वो बड़ा बुरा लग रहा करते हुए लेकिन ये perfume है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=141.9, end=142.6, role='comedian', content='Okay।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=143.0, end=143.6, role='comedian', content='हाँ।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=144.0, end=145.4, role='comedian', content='तो अगर 50,000 रुपए...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=145.6, end=147.5, role='comedian', content='वो जीता तो आप अपना ही perfume दे दोगे।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=147.6, end=148.5, role='comedian', content='Perfume दे दो।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=148.6, end=149.3, role='comedian', content='But।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=149.4, end=152.0, role='comedian', content='जैसे मैं आपसे दो-तीन बार मिला हूँ, अगर आपके पास ये था...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=152.3, end=152.9, role='comedian', content='हाँ।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=153.2, end=154.8, role='audience', content='[audience laughter]', reaction_type='laughter'), AudienceEvent(start=155.2, end=156.0, role='audience', content='[audience applause]', reaction_type='applause'), AudienceEvent(start=156.5, end=157.2, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=157.8, end=159.6, role='comedian', content='ठीक है। आह कौस्तुभ आपका stake पे क्या है?', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=160.0, end=162.5, role='comedian', content='यार मैं एक लाया हूँ देखो जो मुझे मिला है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=162.7, end=163.2, role='comedian', content='हम्म।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=163.6, end=164.5, role='comedian', content='आह वो है...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=164.9, end=166.4, role='comedian', content='मेरा बड़ा कीमती...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=166.8, end=168.6, role='comedian', content='भाई एक मेरे दोस्त के earphones हैं।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=169.0, end=169.6, role='comedian', content='ओह।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=170.0, end=171.0, role='comedian', content='है ना ये मुझे...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=171.4, end=173.3, role='comedian', content='बहुत पसंद आए थे क्योंकि किसको पता नहीं है मैंने मेरे पास हैं।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=173.8, end=174.3, role='comedian', content='अच्छा।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=174.7, end=175.6, role='comedian', content=\"It's very important to me।\", event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=176.0, end=177.3, role='comedian', content='इसका stake थोड़ी वो है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=177.8, end=178.2, role='comedian', content='है ना?', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=178.6, end=179.1, role='comedian', content='नहीं।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=179.6, end=180.4, role='comedian', content='ये तो मैं रख लूँ।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=180.8, end=182.8, role='comedian', content='पर तुझे पता है चोरी की definition क्या होती है?', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=183.3, end=184.0, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=184.5, end=184.9, role='comedian', content='Cool है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=185.3, end=186.0, role='comedian', content='आह।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=186.5, end=188.4, role='comedian', content='हम लोग ready हैं contestant के लिए।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=188.9, end=191.5, role='comedian', content='मैं बता देता हूँ कि इस contestant के बारे में हमें पहले से कुछ भी नहीं पता है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=192.0, end=193.5, role='comedian', content='Zero idea at all।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=194.0, end=196.0, role='comedian', content='ना ये पता है कि पुरुष है, महिला है, क्या इनकी जानकारी है, nothing at all।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=196.5, end=197.7, role='comedian', content='We have to...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=198.2, end=199.3, role='comedian', content='to judge this person totally in front of you...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=199.8, end=201.5, role='comedian', content='तो तुम लोग भी बराबर idea है कि कौन आ रहा है और हमें बराबर idea है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=202.0, end=203.0, role='comedian', content='है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=203.5, end=205.1, role='comedian', content='मेरी team ने उन्हें चुना है, मेरी team पीछे बैठी हुई है और...', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=205.6, end=207.4, role='comedian', content='तो इन्होंने मेरे को info दिया जो आपके सामने पढ़ रहा हूँ।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=207.9, end=209.7, role='comedian', content='जो first contestant है उनकी info ये है कि उनका नाम है Ananya Yadav।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=210.2, end=211.7, role='comedian', content='Ananya 22 साल की हैं। आह ये दो brand और एक company के लिए freelance content का काम करती हैं।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=212.2, end=213.5, role='comedian', content='Already no respect।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=214.1, end=214.5, role='comedian', content='Okay।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=215.0, end=216.1, role='comedian', content='Also unemployed।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=216.7, end=217.5, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=218.0, end=220.2, role='comedian', content='अब कुछ random facts इनके बारे में। इस लड़की को check भरते हुए anxiety होती है।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=220.8, end=221.2, role='comedian', content='है।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=221.7, end=222.4, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=222.9, end=225.5, role='comedian', content='आह इनको words के spellings और लोगों के नाम बिल्कुल याद नहीं रहते हैं। Okay।', event_type='speech', delivery_tag='deadpan'), ComedianEvent(start=226.0, end=226.6, role='comedian', content='Okay।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=227.1, end=227.9, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=228.4, end=228.9, role='comedian', content='ये show की winning amount से अपने parents के लिए कुछ super cute करेगी।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=229.4, end=230.2, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=230.7, end=231.9, role='comedian', content='ओह।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=232.3, end=233.0, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=233.5, end=235.7, role='comedian', content='भैया budget देख रहे हो KBC में होता है घर खरीदने की इधर लेंगे।', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=236.2, end=237.0, role='audience', content='[audience laughter]', reaction_type='laughter'), ComedianEvent(start=237.5, end=239.5, role='comedian', content='यहाँ पे कुछ super cute...', event_type='speech', delivery_tag='deadpan'), AudienceEvent(start=240.0, end=240.8, role='audience', content='[audience laughter]', reaction_type='laughter')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T13:59:58.983932Z",
     "start_time": "2025-11-23T12:11:21.555602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "OUTPUT_FILE = DATASET_DIR / \"inference_results.jsonl\"\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    pass\n",
    "\n",
    "def process_and_save_chunk(chunk):\n",
    "    try:\n",
    "        user_messages = get_segmented_audio_with_timestamps(\n",
    "            AUDIO_DIR,\n",
    "            chunk,\n",
    "            segment_duration=4  # Adjust to 4-8s as needed\n",
    "        )\n",
    "\n",
    "        inference_result = chain.invoke({\n",
    "            \"user_messages\": user_messages,\n",
    "            \"schema\": ComedySession.model_json_schema(),\n",
    "        })\n",
    "\n",
    "        chunk_data = chunk.model_dump() if hasattr(chunk, 'model_dump') else vars(chunk)\n",
    "\n",
    "        combined_record = {\n",
    "            \"chunk_metadata\": chunk_data,\n",
    "            \"inference\": inference_result.model_dump()\n",
    "        }\n",
    "\n",
    "        with file_lock:\n",
    "            with open(OUTPUT_FILE, 'a') as f:\n",
    "                f.write(json.dumps(combined_record) + \"\\n\")\n",
    "        return combined_record\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed on chunk {chunk}: {str(e)}\")\n",
    "\n",
    "results = []\n",
    "num_workers = 128\n",
    "\n",
    "print(f\"Starting processing with {num_workers} workers. Saving to {OUTPUT_FILE}...\")\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    future_to_chunk = {\n",
    "        executor.submit(process_and_save_chunk, chunk): chunk\n",
    "        for chunk in chunk_lst\n",
    "    }\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_chunk), total=len(chunk_lst)):\n",
    "        chunk = future_to_chunk[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "        except Exception as exc:\n",
    "            tqdm.write(f\"Error processing {chunk.file} [{chunk.start}-{chunk.end}]: {exc}\")\n",
    "\n",
    "print(f\"\\nProcessing complete. {len(results)} chunks successfully processed.\")"
   ],
   "id": "fde163a238337120",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing with 128 workers. Saving to /Users/riverfog7/Workspace/SCA/data_prep/dataset/inference_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 445/660 [1:16:17<36:51, 10.29s/it]  \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AudioSlice' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mLengthFinishReasonError\u001B[39m                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mprocess_and_save_chunk\u001B[39m\u001B[34m(chunk)\u001B[39m\n\u001B[32m      9\u001B[39m user_messages = get_segmented_audio_with_timestamps(\n\u001B[32m     10\u001B[39m     AUDIO_DIR,\n\u001B[32m     11\u001B[39m     chunk,\n\u001B[32m     12\u001B[39m     segment_duration=\u001B[32m4\u001B[39m  \u001B[38;5;66;03m# Adjust to 4-8s as needed\u001B[39;00m\n\u001B[32m     13\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m inference_result = \u001B[43mchain\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m     16\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43muser_messages\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_messages\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     17\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mschema\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mComedySession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_json_schema\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     18\u001B[39m \u001B[43m\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m chunk_data = chunk.model_dump() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(chunk, \u001B[33m'\u001B[39m\u001B[33mmodel_dump\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mvars\u001B[39m(chunk)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3129\u001B[39m, in \u001B[36mRunnableSequence.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3128\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3129\u001B[39m                 input_ = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3130\u001B[39m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/retry.py:201\u001B[39m, in \u001B[36mRunnableRetry.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    197\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    198\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    199\u001B[39m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Input, config: RunnableConfig | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m, **kwargs: Any\n\u001B[32m    200\u001B[39m ) -> Output:\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_invoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2050\u001B[39m, in \u001B[36mRunnable._call_with_config\u001B[39m\u001B[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001B[39m\n\u001B[32m   2047\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(child_config) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[32m   2048\u001B[39m         output = cast(\n\u001B[32m   2049\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mOutput\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m-> \u001B[39m\u001B[32m2050\u001B[39m             \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2051\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m   2052\u001B[39m \u001B[43m                \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2053\u001B[39m \u001B[43m                \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2054\u001B[39m \u001B[43m                \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2055\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2056\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2057\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m   2058\u001B[39m         )\n\u001B[32m   2059\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/config.py:428\u001B[39m, in \u001B[36mcall_func_with_variable_args\u001B[39m\u001B[34m(func, input, config, run_manager, **kwargs)\u001B[39m\n\u001B[32m    427\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m] = run_manager\n\u001B[32m--> \u001B[39m\u001B[32m428\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/retry.py:186\u001B[39m, in \u001B[36mRunnableRetry._invoke\u001B[39m\u001B[34m(self, input_, run_manager, config, **kwargs)\u001B[39m\n\u001B[32m    179\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_invoke\u001B[39m(\n\u001B[32m    180\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    181\u001B[39m     input_: Input,\n\u001B[32m   (...)\u001B[39m\u001B[32m    184\u001B[39m     **kwargs: Any,\n\u001B[32m    185\u001B[39m ) -> Output:\n\u001B[32m--> \u001B[39m\u001B[32m186\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sync_retrying\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreraise\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    187\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:445\u001B[39m, in \u001B[36mBaseRetrying.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    444\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m445\u001B[39m     do = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    446\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001B[39m, in \u001B[36mBaseRetrying.iter\u001B[39m\u001B[34m(self, retry_state)\u001B[39m\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iter_state.actions:\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m     result = \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:420\u001B[39m, in \u001B[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001B[39m\u001B[34m(rs)\u001B[39m\n\u001B[32m    419\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.reraise:\n\u001B[32m--> \u001B[39m\u001B[32m420\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43mretry_exc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    421\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mfut\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexception\u001B[39;00m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:187\u001B[39m, in \u001B[36mRetryError.reraise\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    186\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.last_attempt.failed:\n\u001B[32m--> \u001B[39m\u001B[32m187\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlast_attempt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    400\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m     \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/retry.py:188\u001B[39m, in \u001B[36mRunnableRetry._invoke\u001B[39m\u001B[34m(self, input_, run_manager, config, **kwargs)\u001B[39m\n\u001B[32m    187\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m attempt:\n\u001B[32m--> \u001B[39m\u001B[32m188\u001B[39m     result = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    189\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    190\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_patch_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m attempt.retry_state.outcome \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m attempt.retry_state.outcome.failed:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5534\u001B[39m, in \u001B[36mRunnableBindingBase.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5527\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5528\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m   5529\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5532\u001B[39m     **kwargs: Any | \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   5533\u001B[39m ) -> Output:\n\u001B[32m-> \u001B[39m\u001B[32m5534\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbound\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   5535\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   5536\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5537\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5538\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3127\u001B[39m, in \u001B[36mRunnableSequence.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3126\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m i == \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m3127\u001B[39m     input_ = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3128\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5534\u001B[39m, in \u001B[36mRunnableBindingBase.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5527\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5528\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m   5529\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5532\u001B[39m     **kwargs: Any | \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   5533\u001B[39m ) -> Output:\n\u001B[32m-> \u001B[39m\u001B[32m5534\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbound\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   5535\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   5536\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5537\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5538\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:385\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    380\u001B[39m config = ensure_config(config)\n\u001B[32m    381\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    382\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mAIMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    383\u001B[39m     cast(\n\u001B[32m    384\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m385\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    395\u001B[39m     ).message,\n\u001B[32m    396\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1104\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1103\u001B[39m prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1104\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:914\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    912\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    913\u001B[39m     results.append(\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m            \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m     )\n\u001B[32m    921\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1208\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1207\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1208\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1209\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1210\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1211\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1333\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1332\u001B[39m         e.response = raw_response.http_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1333\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m   1334\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   1335\u001B[39m     \u001B[38;5;28mself\u001B[39m.include_response_headers\n\u001B[32m   1336\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1337\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1338\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1305\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1300\u001B[39m     raw_response = (\n\u001B[32m   1301\u001B[39m         \u001B[38;5;28mself\u001B[39m.root_client.chat.completions.with_raw_response.parse(\n\u001B[32m   1302\u001B[39m             **payload\n\u001B[32m   1303\u001B[39m         )\n\u001B[32m   1304\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1305\u001B[39m     response = \u001B[43mraw_response\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1306\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m openai.BadRequestError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/openai/_legacy_response.py:139\u001B[39m, in \u001B[36mLegacyAPIResponse.parse\u001B[39m\u001B[34m(self, to)\u001B[39m\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_given(\u001B[38;5;28mself\u001B[39m._options.post_parser):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     parsed = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparsed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(parsed, BaseModel):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:178\u001B[39m, in \u001B[36mCompletions.parse.<locals>.parser\u001B[39m\u001B[34m(raw_completion)\u001B[39m\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mparser\u001B[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_parse_chat_completion\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m        \u001B[49m\u001B[43mchat_completion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mraw_completion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    181\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_tools\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchat_completion_tools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/openai/lib/_parsing/_completions.py:100\u001B[39m, in \u001B[36mparse_chat_completion\u001B[39m\u001B[34m(response_format, input_tools, chat_completion)\u001B[39m\n\u001B[32m     99\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m choice.finish_reason == \u001B[33m\"\u001B[39m\u001B[33mlength\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m100\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m LengthFinishReasonError(completion=chat_completion)\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m choice.finish_reason == \u001B[33m\"\u001B[39m\u001B[33mcontent_filter\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[31mLengthFinishReasonError\u001B[39m: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=3456, total_tokens=11648, completion_tokens_details=None, prompt_tokens_details=None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 48\u001B[39m\n\u001B[32m     47\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     result = \u001B[43mfuture\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     49\u001B[39m     results.append(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    400\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m     \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/thread.py:59\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 33\u001B[39m, in \u001B[36mprocess_and_save_chunk\u001B[39m\u001B[34m(chunk)\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed on chunk \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchunk\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mRuntimeError\u001B[39m: Failed on chunk start_time=4452.15 end_time=4571.8 file='Judge Me If You Can! Ep01 ft. @ComicKaustubhAgarwal & @yuvrajdua4094.flac': Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=3456, total_tokens=11648, completion_tokens_details=None, prompt_tokens_details=None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 51\u001B[39m\n\u001B[32m     49\u001B[39m             results.append(result)\n\u001B[32m     50\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m             tqdm.write(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mError processing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchunk.file\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchunk.end\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     53\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mProcessing complete. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(results)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m chunks successfully processed.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/pydantic/main.py:1026\u001B[39m, in \u001B[36mBaseModel.__getattr__\u001B[39m\u001B[34m(self, item)\u001B[39m\n\u001B[32m   1023\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__getattribute__\u001B[39m(item)  \u001B[38;5;66;03m# Raises AttributeError if appropriate\u001B[39;00m\n\u001B[32m   1024\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1025\u001B[39m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mAttributeError\u001B[39m: 'AudioSlice' object has no attribute 'start'"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
