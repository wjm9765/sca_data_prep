# 1. í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ dataset[i]ê°€ 4ë§Œ í† í° ì´ë‚´ì¸ì§€ ì²´í¬
# 2. target audioì— ì˜ë¯¸ ì—†ëŠ” 1ì´ˆ ì´í•˜ ì˜¤ë””ì˜¤ê°€ ìˆëŠ”ì§€ ì²´í¬ (ë„ˆë¬´ ì§§ì€ ì˜¤ë””ì˜¤, ë¬¸ì¥ ë“±)
# 3. user ìƒ˜í”Œë§ 16000Hz, assistant ìƒ˜í”Œë§ 24000Hz ì²´í¬
# 4. ì „ì²´ êµ¬ì¡°ê°€ ì˜ë„í•œëŒ€ë¡œ ë‚˜ì™”ëŠ”ì§€ ì²´í¬ 
# 5. speaker_embeddingì´ ì œëŒ€ë¡œ ìˆëŠ”ì§€, ì‹¤íŒ¨í•´ì„œ 0ìœ¼ë¡œ ì±„ì›Œì§€ì§€ ì•Šì•˜ëŠ”ì§€ 
# 6. ì‹œìŠ¤í…œí”„ë¡¬í”„íŠ¸ ìˆëŠ”ì§€ , ì‹œí€€ìŠ¤ êµ¬ì¡°ê°€ ë§ëŠ”ì§€ 4 2 4 2 4 2 .. 
#7 . target_audio ëŠ” ì–´ë–»ê²Œ ì €ì¥ë˜ì–´ìˆëŠ”ì§€ í™•ì¸ 

#!/usr/bin/env -S uv run python
#!/usr/bin/env -S uv run python

import numpy as np
from pathlib import Path
from tqdm import tqdm
import textwrap
import soundfile as sf  # ì˜¤ë””ì˜¤ ì €ì¥ìš© (ì—†ìœ¼ë©´ pip install soundfile)
from transformers import Qwen3OmniMoeProcessor # í† í¬ë‚˜ì´ì € ë¡œë“œìš©
DEFAULT_INPUT_DIR = Path("./Multi-stream Spontaneous Conversation Training Dataset")
DEBUG_OUTPUT_DIR = Path("./test_output") # ë³µì›ëœ ì˜¤ë””ì˜¤/í…ìŠ¤íŠ¸ ì €ì¥ ê²½ë¡œ

NUM_SAMPLES_TO_CHECK = 100

# [Import]
try:
    from src.sca_data.dataset_utils import easy_load, DuplexConfig, AudioSeg, Audio
except ImportError:
    from sca_data.dataset_utils import easy_load, DuplexConfig, AudioSeg, Audio

def print_separator(title):
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")

def verify_dataset():
    print_separator("ë°ì´í„°ì…‹ ë¡œë“œ ë° ê²€ì¦ ì‹œì‘")
    
    # -------------------------------------------------------------------------
    # 0. í† í¬ë‚˜ì´ì € ë¡œë“œ (ë””ì½”ë”©ìš©)
    # -------------------------------------------------------------------------
    print(">>> í† í¬ë‚˜ì´ì € ë¡œë“œ ì¤‘ (Qwen/Qwen3-Omni-30B-A3B-Instruct)...")
    try:
        processor = Qwen3OmniMoeProcessor.from_pretrained(
            "Qwen/Qwen3-Omni-30B-A3B-Instruct", 
            trust_remote_code=True
        )
        tokenizer = processor.tokenizer
    except Exception as e:
        print(f"âš ï¸ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {e}\n(í…ìŠ¤íŠ¸ ë””ì½”ë”© ê¸°ëŠ¥ì´ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        tokenizer = None

    # -------------------------------------------------------------------------
    # 1. ë°ì´í„°ì…‹ ë¡œë“œ
    # -------------------------------------------------------------------------
    try:
        #ds = easy_load(DEFAULT_INPUT_DIR, format="duplex")
        ds = easy_load(format="duplex")
        total_len = len(ds)
        
        if NUM_SAMPLES_TO_CHECK is not None and NUM_SAMPLES_TO_CHECK < total_len:
            print(f"âœ‚ï¸  ì„¤ì •ì— ë”°ë¼ ì•ë¶€ë¶„ {NUM_SAMPLES_TO_CHECK}ê°œë§Œ ì˜ë¼ì„œ ê²€ì¦í•©ë‹ˆë‹¤.")
            ds = ds.select(range(NUM_SAMPLES_TO_CHECK))
        print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ! ì´ ìƒ˜í”Œ ìˆ˜: {len(ds)}")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # í†µê³„ ë³€ìˆ˜
    stats = {
        "max_seq_len": 0,
        "min_seq_len": 999999,
        "total_tokens": 0,
        "over_40k_count": 0,
        "short_target_audio_count": 0, 
        "zero_embedding_count": 0,
        "sr_mismatch_count": 0,
        "structure_error_count": 0,
    }

    # ìƒìˆ˜ ì„¤ì •
    AUDIO_TOKEN = -100
    SILENCE_TOKEN = 151646 # [ì¤‘ìš”] ìƒì„± ì½”ë“œì™€ ì¼ì¹˜ì‹œí‚´
    AUDIO_RATIO = 4
    TEXT_SLICE = 2
    
    # ë””ë²„ê·¸ í´ë” ìƒì„±
    DEBUG_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # -------------------------------------------------------------------------
    # 2. ì „ì²´ ë°ì´í„° ìˆœíšŒ
    # -------------------------------------------------------------------------
    for i, sample in enumerate(tqdm(ds, desc="ê²€ì¦ ì§„í–‰ ì¤‘")):
        
        row = sample["dataset_row_obj"]
        seq_len = len(row.input_sequence)
        
        # [í†µê³„ ì§‘ê³„]
        stats["max_seq_len"] = max(stats["max_seq_len"], seq_len)
        stats["min_seq_len"] = min(stats["min_seq_len"], seq_len)
        stats["total_tokens"] += seq_len
        
        # =====================================================================
        # [New Feature] 1. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ & í…ìŠ¤íŠ¸ ë³µì› ê²€ì¦ (Sample 0ë§Œ ìƒì„¸ ì¶œë ¥)
        # =====================================================================
        if i == 0 and tokenizer is not None:
            print_separator(f"[Sample 0] ìƒì„¸ ë””ì½”ë”© ë¶„ì„")
            
            # (1) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í™•ì¸
            try:
                first_audio_idx = row.input_sequence.index(AUDIO_TOKEN)
                sys_prompt_ids = row.input_sequence[:first_audio_idx]
                sys_text = tokenizer.decode(sys_prompt_ids)
                print(f"ğŸ”¹ [System Prompt ë””ì½”ë”© ê²°ê³¼]:\n{textwrap.fill(sys_text, width=80)}\n")
            except ValueError:
                print("âŒ ì˜¤ë””ì˜¤ í† í°(-100)ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ë¦¬í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # (2) Target Audio <-> Text ë§¤í•‘ ë³µì›
            print(f"ğŸ”¹ [Target Audio & Text ë§¤í•‘ ë³µì›] (ì´ {len(row.target_audios)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¤‘ ì• 5ê°œë§Œ ì¶œë ¥)")
            
            full_reconstructed_text = []
            
            for seg_idx, seg in enumerate(row.target_audios):
                # ì¸ë±ìŠ¤ë¡œ ì‹¤ì œ í† í° ID ê°€ì ¸ì˜¤ê¸°
                token_ids = [row.input_sequence[idx] for idx in seg.text_token_idxs]
                
                # ë””ì½”ë”©
                decoded_text = tokenizer.decode(token_ids)
                full_reconstructed_text.append(decoded_text)
                
                # ì˜¤ë””ì˜¤ ì •ë³´
                duration = len(seg.audio.waveform) / seg.audio.sampling_rate
                
                # ìƒìœ„ 5ê°œë§Œ ë¡œê·¸ ì¶œë ¥
                if seg_idx < 5:
                    print(f"  Start[{seg.text_token_idxs[0]}] -> Text: \"{decoded_text.strip()}\" | Audio: {duration:.2f}s")
                    
                    # (ì„ íƒ) ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ - ì‹¤ì œë¡œ ë“¤ì–´ë³´ê³  ì‹¶ìœ¼ë©´ ì£¼ì„ í•´ì œ
                    # sf.write(DEBUG_OUTPUT_DIR / f"sample0_seg{seg_idx}_{decoded_text.strip()[:10]}.wav", seg.audio.waveform, 24000)

            print(f"\nğŸ”¹ [ì „ì²´ ëŒ€í™” íë¦„ ë³µì›]:\n{' '.join(full_reconstructed_text)[:200]} ... (ì¤‘ëµ)")
            print_separator("êµ¬ì¡° ê²€ì¦ ê³„ì† ì§„í–‰")

        # =====================================================================
        # [Existing Checks] ê¸°ì¡´ ê²€ì¦ ë¡œì§ ìœ ì§€
        # =====================================================================
        
        # 1. ê¸¸ì´ 4ë§Œ í† í° ì²´í¬
        if seq_len > 40000:
            stats["over_40k_count"] += 1
            if stats["over_40k_count"] == 1:
                print(f"\nâŒ [Sample {i}] ê¸¸ì´ ì´ˆê³¼ ë°œê²¬: {seq_len} tokens")

        # 2. Target Audio 1ì´ˆ ì´í•˜ ì²´í¬
        for audio_seg in row.target_audios:
            duration = len(audio_seg.audio.waveform) / 24000.0
            if duration < 1.0:
                stats["short_target_audio_count"] += 1

        # 3. ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì²´í¬
        if row.input_audios and row.input_audios[0].sampling_rate != 16000:
            stats["sr_mismatch_count"] += 1
        
        if row.target_audios and row.target_audios[0].audio.sampling_rate != 24000:
            stats["sr_mismatch_count"] += 1

        # 5. Speaker Embedding ì²´í¬
        emb = np.array(row.speaker_embedding)
        if np.all(emb == 0):
            stats["zero_embedding_count"] += 1
            if stats["zero_embedding_count"] == 1:
                print(f"\nâŒ [Sample {i}] Speaker Embeddingì´ ëª¨ë‘ 0ì…ë‹ˆë‹¤. (ì´í›„ ìƒëµ)")

        # 6. êµ¬ì¡° íŒ¨í„´ ì²´í¬ (Silence 1ê°œ, Text 2ê°œ ë™ì  ëŒ€ì‘)
        try:
            try:
                first_audio_idx = row.input_sequence.index(AUDIO_TOKEN)
            except ValueError:
                continue

            if len(row.input_sequence[:first_audio_idx]) == 0:
                if stats["structure_error_count"] == 0:
                    print(f"\nâŒ [Sample {i}] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ëˆ„ë½")
                stats["structure_error_count"] += 1
            
            body_seq = row.input_sequence[first_audio_idx:]
            cursor = 0
            
            while cursor < len(body_seq):
                # (A) ì˜¤ë””ì˜¤ 4ê°œ
                audio_part = body_seq[cursor : cursor + AUDIO_RATIO]
                if len(audio_part) < AUDIO_RATIO: break 

                if not all(t == AUDIO_TOKEN for t in audio_part):
                    if stats["structure_error_count"] == 0:
                        print(f"\nâŒ [Sample {i}] ì˜¤ë””ì˜¤ íŒ¨í„´ ê¹¨ì§: {audio_part}")
                    stats["structure_error_count"] += 1
                    break
                
                cursor += AUDIO_RATIO 

                # (B) í…ìŠ¤íŠ¸/ì¹¨ë¬µ
                if cursor >= len(body_seq): break
                first_token = body_seq[cursor]

                if first_token == SILENCE_TOKEN:
                    cursor += 1 # ì¹¨ë¬µ 1ê°œ
                else:
                    text_part = body_seq[cursor : cursor + TEXT_SLICE]
                    if len(text_part) < TEXT_SLICE: break 
                    if any(t == AUDIO_TOKEN for t in text_part):
                        if stats["structure_error_count"] == 0:
                            print(f"\nâŒ [Sample {i}] í…ìŠ¤íŠ¸ íŒ¨í„´ ê¹¨ì§: {text_part}")
                        stats["structure_error_count"] += 1
                        break
                    cursor += TEXT_SLICE 

        except Exception as e:
            if stats["structure_error_count"] == 0:
                print(f"\nâŒ [Sample {i}] ê²€ì¦ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            stats["structure_error_count"] += 1

    # ---------------------------------------------------------------------
    # ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
    # ---------------------------------------------------------------------
    avg_len = stats["total_tokens"] / len(ds) if len(ds) > 0 else 0
    
    print_separator("ğŸ“Š í† í° ê¸¸ì´ í†µê³„")
    print(f"â–¶ ìµœì†Œ ê¸¸ì´: {stats['min_seq_len']} tokens")
    print(f"â–¶ ìµœëŒ€ ê¸¸ì´: {stats['max_seq_len']} tokens (Limit: 40000)")
    print(f"â–¶ í‰ê·  ê¸¸ì´: {avg_len:.2f} tokens")

    print_separator("ğŸ›  ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    print(f"1. 4ë§Œ í† í° ì´ˆê³¼ ìƒ˜í”Œ ìˆ˜ : {stats['over_40k_count']} ê°œ")
    print(f"2. êµ¬ì¡° íŒ¨í„´ ì—ëŸ¬ ìƒ˜í”Œ ìˆ˜ : {stats['structure_error_count']} ê°œ")
    print(f"3. SR ë¶ˆì¼ì¹˜ ìƒ˜í”Œ ìˆ˜    : {stats['sr_mismatch_count']} ê°œ")
    print(f"4. 1ì´ˆ ë¯¸ë§Œ ì˜¤ë””ì˜¤ ê°œìˆ˜  : {stats['short_target_audio_count']} ê°œ (ì°¸ê³ ìš©)")
    
    emb_status = "âœ… ì •ìƒ"
    if stats['zero_embedding_count'] > 0:
        emb_status = f"âŒ ì‹¤íŒ¨ ({stats['zero_embedding_count']} / {len(ds)} ìƒ˜í”Œì´ 0ìœ¼ë¡œ ì±„ì›Œì§)"
    print(f"5. Speaker Embedding    : {emb_status}")

    if (stats['over_40k_count'] == 0 and 
        stats['sr_mismatch_count'] == 0 and 
        stats['structure_error_count'] == 0):
        print("\nğŸ‰ [SUCCESS] ë°ì´í„°ì…‹ êµ¬ì¡° ê²€ì¦ í†µê³¼!")
    else:
        print("\nğŸ”¥ [FAILURE] ë°ì´í„°ì…‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìš”ì•½ì„ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    verify_dataset()